[2019-03-18 17:01:27,147] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:08:08,087] INFO Reading configuration from: /data/bdata/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:08:08,102] INFO Resolved hostname: bdata3 to address: bdata3/192.168.33.202 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,102] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,102] INFO Resolved hostname: bdata1 to address: bdata1/192.168.33.200 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,102] INFO Defaulting to majority quorums (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:08:08,106] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:08:08,106] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:08:08,106] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:08:08,116] INFO Starting quorum peer (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-03-18 17:08:08,122] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-03-18 17:08:08,125] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:08:08,130] INFO tickTime set to 2000 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,130] INFO initLimit set to 5 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,130] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,130] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,135] INFO QuorumPeer communication is not secured! (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,136] INFO quorum.cnxn.threads.size set to 20 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,137] INFO Reading snapshot /data/bdata/data/zookeeper/version-2/snapshot.a00000ab4 (org.apache.zookeeper.server.persistence.FileSnap)
[2019-03-18 17:08:08,211] INFO My election bind port: bdata1/192.168.33.200:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:08:08,215] INFO LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,215] INFO New election. My id =  1, proposed zxid=0xa000011ef (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:08:08,217] INFO Notification: 1 (message format version), 1 (n.leader), 0xa000011ef (n.zxid), 0x1 (n.round), LOOKING (n.state), 1 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:08:08,219] INFO Have smaller server identifier, so dropping the connection: (2, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:08:08,220] INFO Have smaller server identifier, so dropping the connection: (3, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:08:08,220] INFO Received connection request /192.168.33.201:54944 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:08:08,224] INFO Received connection request /192.168.33.202:37326 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:08:08,225] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:08:08,225] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:08:08,226] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:08:08,227] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:08:08,227] INFO FOLLOWING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,229] INFO TCP NoDelay set to: true (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:08:08,232] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:host.name=bdata1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.version=1.8.0_201 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,232] INFO Server environment:user.dir=/data/bdata (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,234] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /data/bdata/data/zookeeper/version-2 snapdir /data/bdata/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:08,234] INFO FOLLOWING - LEADER ELECTION TOOK - 19 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:08:08,235] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:08:08,238] INFO Getting a diff from the leader 0xa00001202 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:08:08,240] WARN Got zxid 0xa000011f0 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:08:08,252] INFO Creating new log file: log.a000011f0 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-03-18 17:08:08,652] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-03-18 17:08:09,023] INFO starting (kafka.server.KafkaServer)
[2019-03-18 17:08:09,024] INFO Connecting to zookeeper on bdata1:2181,bdata2:2181,bdata3:2181 (kafka.server.KafkaServer)
[2019-03-18 17:08:09,037] INFO [ZooKeeperClient] Initializing a new session to bdata1:2181,bdata2:2181,bdata3:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:08:09,040] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:host.name=bdata1 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,040] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,041] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,041] INFO Client environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,041] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,041] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,041] INFO Client environment:user.dir=/data/bdata (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,041] INFO Initiating client connection, connectString=bdata1:2181,bdata2:2181,bdata3:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35047d03 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:08:09,050] INFO Opening socket connection to server bdata1/192.168.33.200:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:08:09,051] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:08:09,053] INFO Socket connection established to bdata1/192.168.33.200:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:08:09,055] INFO Accepted socket connection from /192.168.33.200:53538 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:08:09,058] INFO Client attempting to establish new session at /192.168.33.200:53538 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:09,059] WARN Got zxid 0xa00001203 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:08:09,063] INFO Established session 0x10000888d840000 with negotiated timeout 6000 for client /192.168.33.200:53538 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:08:09,064] INFO Session establishment complete on server bdata1/192.168.33.200:2181, sessionid = 0x10000888d840000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:08:09,066] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:08:09,346] INFO Cluster ID = adFAhm5OQBqsZXG4dKyvBA (kafka.server.KafkaServer)
[2019-03-18 17:08:09,558] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = bdata1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /data/bdata/logs/kafka/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = bdata1:2181,bdata2:2181,bdata3:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-03-18 17:08:09,565] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = bdata1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /data/bdata/logs/kafka/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = bdata1:2181,bdata2:2181,bdata3:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-03-18 17:08:09,626] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:08:09,626] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:08:09,628] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:08:09,664] INFO Loading logs. (kafka.log.LogManager)
[2019-03-18 17:08:09,930] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:08:09,933] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,137] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,138] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 453 ms (kafka.log.Log)
[2019-03-18 17:08:10,150] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:08:10,151] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,155] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,155] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-03-18 17:08:10,160] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:08:10,160] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,164] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,164] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-03-18 17:08:10,172] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:08:10,172] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,240] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,240] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2019-03-18 17:08:10,247] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:08:10,248] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,250] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:08:10,251] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-03-18 17:08:10,255] INFO Logs loading complete in 591 ms. (kafka.log.LogManager)
[2019-03-18 17:08:10,263] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-03-18 17:08:10,264] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-03-18 17:08:10,477] INFO Awaiting socket connections on bdata1:9092. (kafka.network.Acceptor)
[2019-03-18 17:08:10,500] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-03-18 17:08:10,517] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:08:10,517] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:08:10,523] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:08:10,539] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-03-18 17:08:10,629] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-03-18 17:08:10,637] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-03-18 17:08:10,638] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(bdata1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-03-18 17:08:10,725] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:08:10,728] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:08:10,731] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:08:10,774] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-03-18 17:08:10,787] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-03-18 17:08:10,822] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 35 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:08:10,870] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2019-03-18 17:08:10,912] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-03-18 17:08:10,936] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-03-18 17:08:10,961] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-03-18 17:08:11,018] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-03-18 17:08:11,063] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-03-18 17:08:11,087] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-18 17:08:11,087] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-18 17:08:11,088] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-03-18 17:08:11,127] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test4-1, test3-0, test2-1, test4-0, test4-2) (kafka.server.ReplicaFetcherManager)
[2019-03-18 17:08:11,161] INFO Replica loaded for partition test2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,164] INFO [Partition test2-1 broker=1] test2-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:08:11,191] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,191] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,191] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,191] INFO [Partition test4-0 broker=1] test4-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:08:11,211] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,211] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,211] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,211] INFO [Partition test3-0 broker=1] test3-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:08:11,226] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,226] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,226] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,226] INFO [Partition test4-1 broker=1] test4-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:08:11,240] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,240] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,240] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:08:11,240] INFO [Partition test4-2 broker=1] test4-2 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:10:52,486] INFO Reading configuration from: /data/bdata/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:10:52,495] INFO Resolved hostname: bdata3 to address: bdata3/192.168.33.202 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,495] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,495] INFO Resolved hostname: bdata1 to address: bdata1/192.168.33.200 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,495] INFO Defaulting to majority quorums (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:10:52,498] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:10:52,498] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:10:52,498] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:10:52,507] INFO Starting quorum peer (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-03-18 17:10:52,512] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-03-18 17:10:52,514] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:10:52,519] INFO tickTime set to 2000 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,519] INFO initLimit set to 5 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,519] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,519] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,524] INFO QuorumPeer communication is not secured! (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,524] INFO quorum.cnxn.threads.size set to 20 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,525] INFO Reading snapshot /data/bdata/data/zookeeper/version-2/snapshot.a00000ab4 (org.apache.zookeeper.server.persistence.FileSnap)
[2019-03-18 17:10:52,599] INFO My election bind port: bdata1/192.168.33.200:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:10:52,603] INFO LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,604] INFO New election. My id =  1, proposed zxid=0xa00001257 (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:10:52,606] INFO Notification: 1 (message format version), 1 (n.leader), 0xa00001257 (n.zxid), 0x1 (n.round), LOOKING (n.state), 1 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:10:52,608] INFO Have smaller server identifier, so dropping the connection: (2, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:10:52,609] INFO Have smaller server identifier, so dropping the connection: (3, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:10:52,609] INFO Received connection request /192.168.33.201:54956 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:10:52,611] INFO Received connection request /192.168.33.202:37338 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:10:52,612] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:10:52,612] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:10:52,612] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:10:52,612] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:10:52,613] INFO FOLLOWING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,615] INFO TCP NoDelay set to: true (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:10:52,617] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,617] INFO Server environment:host.name=bdata1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.version=1.8.0_201 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,618] INFO Server environment:user.dir=/data/bdata (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,619] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /data/bdata/data/zookeeper/version-2 snapdir /data/bdata/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:10:52,619] INFO FOLLOWING - LEADER ELECTION TOOK - 16 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:10:52,620] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:10:52,623] INFO Getting a diff from the leader 0xa00001264 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:10:52,624] WARN Got zxid 0xa00001258 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:10:52,632] INFO Creating new log file: log.a00001258 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-03-18 17:10:53,499] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-03-18 17:10:53,862] INFO starting (kafka.server.KafkaServer)
[2019-03-18 17:10:53,863] INFO Connecting to zookeeper on bdata1:2181,bdata2:2181,bdata3:2181 (kafka.server.KafkaServer)
[2019-03-18 17:10:53,875] INFO [ZooKeeperClient] Initializing a new session to bdata1:2181,bdata2:2181,bdata3:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:10:53,879] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:host.name=bdata1 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,879] INFO Client environment:user.dir=/data/bdata (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,880] INFO Initiating client connection, connectString=bdata1:2181,bdata2:2181,bdata3:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35047d03 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:10:53,888] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:10:53,888] INFO Opening socket connection to server bdata3/192.168.33.202:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:10:53,891] INFO Socket connection established to bdata3/192.168.33.202:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:10:53,893] WARN Got zxid 0xa00001265 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:10:53,896] INFO Session establishment complete on server bdata3/192.168.33.202:2181, sessionid = 0x300007f36f0000d, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:10:53,899] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:10:54,093] INFO Cluster ID = adFAhm5OQBqsZXG4dKyvBA (kafka.server.KafkaServer)
[2019-03-18 17:10:54,168] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = bdata1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /data/bdata/logs/kafka/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = bdata1:2181,bdata2:2181,bdata3:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-03-18 17:10:54,181] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = bdata1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /data/bdata/logs/kafka/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = bdata1:2181,bdata2:2181,bdata3:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-03-18 17:10:54,201] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:10:54,203] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:10:54,204] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:10:54,280] INFO Loading logs. (kafka.log.LogManager)
[2019-03-18 17:10:54,354] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:10:54,358] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,388] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,389] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-03-18 17:10:54,398] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:10:54,398] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,401] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,402] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-03-18 17:10:54,407] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:10:54,407] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,411] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,411] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-03-18 17:10:54,415] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:10:54,416] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,420] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,420] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-03-18 17:10:54,428] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:10:54,429] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,431] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:10:54,431] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-03-18 17:10:54,437] INFO Logs loading complete in 157 ms. (kafka.log.LogManager)
[2019-03-18 17:10:54,448] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-03-18 17:10:54,449] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-03-18 17:10:54,762] INFO Awaiting socket connections on bdata1:9092. (kafka.network.Acceptor)
[2019-03-18 17:10:54,797] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-03-18 17:10:54,847] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:10:54,851] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:10:54,851] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:10:54,861] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-03-18 17:10:54,994] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-03-18 17:10:55,005] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-03-18 17:10:55,006] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(bdata1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-03-18 17:10:55,059] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:10:55,059] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:10:55,081] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:10:55,082] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-03-18 17:10:55,091] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-03-18 17:10:55,101] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:10:55,130] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2019-03-18 17:10:55,152] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-03-18 17:10:55,157] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-03-18 17:10:55,176] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-03-18 17:10:55,246] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-03-18 17:10:55,395] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-03-18 17:10:55,419] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-18 17:10:55,419] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-18 17:10:55,420] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-03-18 17:10:55,462] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test4-1, test3-0, test2-1, test4-0, test4-2) (kafka.server.ReplicaFetcherManager)
[2019-03-18 17:10:55,475] INFO Replica loaded for partition test2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,477] INFO [Partition test2-1 broker=1] test2-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:10:55,529] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,529] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,529] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,530] INFO [Partition test4-0 broker=1] test4-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:10:55,559] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,559] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,559] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,560] INFO [Partition test3-0 broker=1] test3-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:10:55,592] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,592] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,592] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,592] INFO [Partition test4-1 broker=1] test4-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:10:55,612] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,613] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,613] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:10:55,613] INFO [Partition test4-2 broker=1] test4-2 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:11:04,205] INFO Accepted socket connection from /192.168.33.200:53582 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:11:04,208] INFO Client attempting to establish new session at /192.168.33.200:53582 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:11:04,219] INFO Established session 0x100008b0fa50000 with negotiated timeout 20000 for client /192.168.33.200:53582 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:13:40,146] WARN Unable to read additional data from client sessionid 0x100008b0fa50000, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:13:40,147] INFO Closed socket connection for client /192.168.33.200:53582 which had sessionid 0x100008b0fa50000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:14:22,341] INFO Reading configuration from: /data/bdata/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:14:22,350] INFO Resolved hostname: bdata3 to address: bdata3/192.168.33.202 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,350] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,350] INFO Resolved hostname: bdata1 to address: bdata1/192.168.33.200 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,350] INFO Defaulting to majority quorums (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:14:22,353] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:14:22,353] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:14:22,353] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:14:22,362] INFO Starting quorum peer (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-03-18 17:14:22,366] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-03-18 17:14:22,368] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:14:22,373] INFO tickTime set to 2000 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,373] INFO initLimit set to 5 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,373] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,373] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,378] INFO QuorumPeer communication is not secured! (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,378] INFO quorum.cnxn.threads.size set to 20 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,379] INFO Reading snapshot /data/bdata/data/zookeeper/version-2/snapshot.a00000ab4 (org.apache.zookeeper.server.persistence.FileSnap)
[2019-03-18 17:14:22,435] INFO My election bind port: bdata1/192.168.33.200:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:22,440] INFO LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,441] INFO New election. My id =  1, proposed zxid=0xa000012c1 (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:22,443] INFO Notification: 1 (message format version), 1 (n.leader), 0xa000012c1 (n.zxid), 0x1 (n.round), LOOKING (n.state), 1 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:22,444] INFO Have smaller server identifier, so dropping the connection: (2, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:22,445] INFO Received connection request /192.168.33.201:54970 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:22,445] INFO Have smaller server identifier, so dropping the connection: (3, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:22,446] INFO Received connection request /192.168.33.202:37352 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:22,447] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:22,447] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:22,447] INFO FOLLOWING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,447] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:22,448] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:22,450] INFO TCP NoDelay set to: true (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:22,452] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:host.name=bdata1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.version=1.8.0_201 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,453] INFO Server environment:user.dir=/data/bdata (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,454] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /data/bdata/data/zookeeper/version-2 snapdir /data/bdata/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:22,454] INFO FOLLOWING - LEADER ELECTION TOOK - 13 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:22,455] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:22,457] INFO Getting a diff from the leader 0xa000012d8 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:22,459] WARN Got zxid 0xa000012c2 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:22,467] INFO Creating new log file: log.a000012c2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-03-18 17:14:26,596] WARN Got zxid 0xa000012d9 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:42,659] INFO Reading configuration from: /data/bdata/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:14:42,670] INFO Resolved hostname: bdata3 to address: bdata3/192.168.33.202 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,671] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,671] INFO Resolved hostname: bdata1 to address: bdata1/192.168.33.200 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,671] INFO Defaulting to majority quorums (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-03-18 17:14:42,675] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:14:42,675] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:14:42,675] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-03-18 17:14:42,684] INFO Starting quorum peer (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-03-18 17:14:42,690] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-03-18 17:14:42,692] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:14:42,697] INFO tickTime set to 2000 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,698] INFO initLimit set to 5 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,698] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,698] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,704] INFO QuorumPeer communication is not secured! (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,704] INFO quorum.cnxn.threads.size set to 20 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,706] INFO Reading snapshot /data/bdata/data/zookeeper/version-2/snapshot.a00000ab4 (org.apache.zookeeper.server.persistence.FileSnap)
[2019-03-18 17:14:42,767] INFO My election bind port: bdata1/192.168.33.200:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:42,775] INFO LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,775] INFO New election. My id =  1, proposed zxid=0xa000012dc (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:42,778] INFO Notification: 1 (message format version), 1 (n.leader), 0xa000012dc (n.zxid), 0x1 (n.round), LOOKING (n.state), 1 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:42,779] INFO Have smaller server identifier, so dropping the connection: (2, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:42,780] INFO Have smaller server identifier, so dropping the connection: (3, 1) (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:42,780] INFO Received connection request /192.168.33.201:54974 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:42,786] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:42,786] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), LEADING (n.state), 2 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:42,789] INFO Received connection request /192.168.33.202:37356 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:14:42,791] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:42,791] INFO FOLLOWING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,792] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:14:42,794] INFO TCP NoDelay set to: true (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:42,797] INFO Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:host.name=bdata1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.version=1.8.0_201 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,797] INFO Server environment:user.dir=/data/bdata (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,798] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /data/bdata/data/zookeeper/version-2 snapdir /data/bdata/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:42,799] INFO FOLLOWING - LEADER ELECTION TOOK - 23 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:42,799] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:14:42,804] INFO Getting a diff from the leader 0xa000012e0 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:42,806] WARN Got zxid 0xa000012dd expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:42,814] INFO Creating new log file: log.a000012dd (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-03-18 17:14:46,666] WARN Got zxid 0xa000012e1 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:14:47,523] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-03-18 17:14:47,876] INFO starting (kafka.server.KafkaServer)
[2019-03-18 17:14:47,877] INFO Connecting to zookeeper on bdata1:2181,bdata2:2181,bdata3:2181 (kafka.server.KafkaServer)
[2019-03-18 17:14:47,893] INFO [ZooKeeperClient] Initializing a new session to bdata1:2181,bdata2:2181,bdata3:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:14:47,896] INFO Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:host.name=bdata1 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.version=1.8.0_201 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.home=/usr/local/jdk/jre (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.class.path=.:/usr/local/jdk/lib/dt.jar:/usr/local/jdk/lib/tools.jar:/usr/local/jdk/jre/lib:/data/bdata/kafka/bin/../libs/activation-1.1.1.jar:/data/bdata/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/argparse4j-0.7.0.jar:/data/bdata/kafka/bin/../libs/audience-annotations-0.5.0.jar:/data/bdata/kafka/bin/../libs/commons-lang3-3.8.1.jar:/data/bdata/kafka/bin/../libs/connect-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-basic-auth-extension-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-file-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-json-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-runtime-2.1.1.jar:/data/bdata/kafka/bin/../libs/connect-transforms-2.1.1.jar:/data/bdata/kafka/bin/../libs/guava-20.0.jar:/data/bdata/kafka/bin/../libs/hk2-api-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-locator-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/hk2-utils-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/jackson-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-core-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-databind-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/data/bdata/kafka/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/data/bdata/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/data/bdata/kafka/bin/../libs/javax.annotation-api-1.2.jar:/data/bdata/kafka/bin/../libs/javax.inject-1.jar:/data/bdata/kafka/bin/../libs/javax.inject-2.5.0-b42.jar:/data/bdata/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/data/bdata/kafka/bin/../libs/javax.ws.rs-api-2.1.jar:/data/bdata/kafka/bin/../libs/jaxb-api-2.3.0.jar:/data/bdata/kafka/bin/../libs/jersey-client-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-common-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-container-servlet-core-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-hk2-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-media-jaxb-2.27.jar:/data/bdata/kafka/bin/../libs/jersey-server-2.27.jar:/data/bdata/kafka/bin/../libs/jetty-client-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-continuation-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-http-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-io-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-security-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-server-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlet-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-servlets-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jetty-util-9.4.12.v20180830.jar:/data/bdata/kafka/bin/../libs/jopt-simple-5.0.4.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka_2.12-2.1.1-sources.jar:/data/bdata/kafka/bin/../libs/kafka-clients-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-log4j-appender-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-examples-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-scala_2.12-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-streams-test-utils-2.1.1.jar:/data/bdata/kafka/bin/../libs/kafka-tools-2.1.1.jar:/data/bdata/kafka/bin/../libs/log4j-1.2.17.jar:/data/bdata/kafka/bin/../libs/lz4-java-1.5.0.jar:/data/bdata/kafka/bin/../libs/maven-artifact-3.6.0.jar:/data/bdata/kafka/bin/../libs/metrics-core-2.2.0.jar:/data/bdata/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/data/bdata/kafka/bin/../libs/plexus-utils-3.1.0.jar:/data/bdata/kafka/bin/../libs/reflections-0.9.11.jar:/data/bdata/kafka/bin/../libs/rocksdbjni-5.14.2.jar:/data/bdata/kafka/bin/../libs/scala-library-2.12.7.jar:/data/bdata/kafka/bin/../libs/scala-logging_2.12-3.9.0.jar:/data/bdata/kafka/bin/../libs/scala-reflect-2.12.7.jar:/data/bdata/kafka/bin/../libs/slf4j-api-1.7.25.jar:/data/bdata/kafka/bin/../libs/slf4j-log4j12-1.7.25.jar:/data/bdata/kafka/bin/../libs/snappy-java-1.1.7.2.jar:/data/bdata/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/data/bdata/kafka/bin/../libs/zkclient-0.11.jar:/data/bdata/kafka/bin/../libs/zookeeper-3.4.13.jar:/data/bdata/kafka/bin/../libs/zstd-jni-1.3.7-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:os.version=3.10.0-693.5.2.el7.x86_64 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,896] INFO Client environment:user.dir=/data/bdata (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,897] INFO Initiating client connection, connectString=bdata1:2181,bdata2:2181,bdata3:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@35047d03 (org.apache.zookeeper.ZooKeeper)
[2019-03-18 17:14:47,905] INFO Opening socket connection to server bdata2/192.168.33.201:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:14:47,906] INFO [ZooKeeperClient] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:14:47,908] INFO Socket connection established to bdata2/192.168.33.201:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:14:47,934] INFO Session establishment complete on server bdata2/192.168.33.201:2181, sessionid = 0x200006f622e001c, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:14:47,937] INFO [ZooKeeperClient] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-03-18 17:14:48,125] INFO Cluster ID = adFAhm5OQBqsZXG4dKyvBA (kafka.server.KafkaServer)
[2019-03-18 17:14:48,191] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = bdata1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /data/bdata/logs/kafka/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = bdata1:2181,bdata2:2181,bdata3:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-03-18 17:14:48,198] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = bdata1
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.1-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /data/bdata/logs/kafka/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = bdata1:2181,bdata2:2181,bdata3:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-03-18 17:14:48,215] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:14:48,215] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:14:48,216] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-03-18 17:14:48,245] INFO Loading logs. (kafka.log.LogManager)
[2019-03-18 17:14:48,289] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:14:48,290] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,314] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,316] INFO [Log partition=test4-2, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-03-18 17:14:48,324] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:14:48,324] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,326] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,327] INFO [Log partition=test4-0, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-03-18 17:14:48,331] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:14:48,331] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,334] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,334] INFO [Log partition=test3-0, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-03-18 17:14:48,338] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:14:48,338] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,341] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,342] INFO [Log partition=test4-1, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-03-18 17:14:48,346] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-03-18 17:14:48,346] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,349] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-03-18 17:14:48,349] INFO [Log partition=test2-1, dir=/data/bdata/logs/kafka/kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-03-18 17:14:48,352] INFO Logs loading complete in 107 ms. (kafka.log.LogManager)
[2019-03-18 17:14:48,360] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-03-18 17:14:48,361] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-03-18 17:14:48,542] INFO Awaiting socket connections on bdata1:9092. (kafka.network.Acceptor)
[2019-03-18 17:14:48,564] INFO [SocketServer brokerId=1] Started 1 acceptor threads (kafka.network.SocketServer)
[2019-03-18 17:14:48,581] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:14:48,582] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:14:48,582] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:14:48,592] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-03-18 17:14:48,643] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-03-18 17:14:48,646] INFO Result of znode creation at /brokers/ids/1 is: OK (kafka.zk.KafkaZkClient)
[2019-03-18 17:14:48,647] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArrayBuffer(EndPoint(bdata1,9092,ListenerName(PLAINTEXT),PLAINTEXT)) (kafka.zk.KafkaZkClient)
[2019-03-18 17:14:48,689] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:14:48,690] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:14:48,693] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-03-18 17:14:48,719] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-03-18 17:14:48,720] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-03-18 17:14:48,724] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:14:48,789] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2019-03-18 17:14:48,810] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-03-18 17:14:48,811] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-03-18 17:14:48,811] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-03-18 17:14:48,848] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-03-18 17:14:48,869] INFO [SocketServer brokerId=1] Started processors for 1 acceptors (kafka.network.SocketServer)
[2019-03-18 17:14:48,885] INFO Kafka version : 2.1.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-18 17:14:48,886] INFO Kafka commitId : 21234bee31165527 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-18 17:14:48,887] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2019-03-18 17:14:48,905] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(test4-1, test3-0, test2-1, test4-0, test4-2) (kafka.server.ReplicaFetcherManager)
[2019-03-18 17:14:48,918] INFO Replica loaded for partition test2-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,921] INFO [Partition test2-1 broker=1] test2-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:14:48,939] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,940] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,940] INFO Replica loaded for partition test4-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,940] INFO [Partition test4-0 broker=1] test4-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:14:48,949] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,950] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,950] INFO Replica loaded for partition test3-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,950] INFO [Partition test3-0 broker=1] test3-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:14:48,957] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,958] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,958] INFO Replica loaded for partition test4-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,958] INFO [Partition test4-1 broker=1] test4-1 starts at Leader Epoch 6 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:14:48,963] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,963] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,963] INFO Replica loaded for partition test4-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-03-18 17:14:48,963] INFO [Partition test4-2 broker=1] test4-2 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-03-18 17:14:59,557] INFO Accepted socket connection from /192.168.33.200:53614 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:14:59,561] INFO Client attempting to establish new session at /192.168.33.200:53614 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:14:59,586] INFO Established session 0x100008e92cb0000 with negotiated timeout 20000 for client /192.168.33.200:53614 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:16:12,774] WARN Connection broken for id 3, my id = 1, error =  (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$RecvWorker.run(QuorumCnxManager.java:1010)
[2019-03-18 17:16:12,776] WARN Interrupting SendWorker (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:16:12,776] WARN Interrupted while waiting for message on queue (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.pollSendQueue(QuorumCnxManager.java:1094)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.access$700(QuorumCnxManager.java:74)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$SendWorker.run(QuorumCnxManager.java:929)
[2019-03-18 17:16:12,776] WARN Send worker leaving thread (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:16:41,785] INFO Received connection request /192.168.33.202:37362 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:16:41,803] INFO Notification: 1 (message format version), 3 (n.leader), 0xa0000131e (n.zxid), 0x1 (n.round), LOOKING (n.state), 3 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:16:42,458] INFO Accepted socket connection from /192.168.33.202:52982 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:16:42,460] INFO Client attempting to establish new session at /192.168.33.202:52982 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:16:42,474] INFO Established session 0x100008e92cb0001 with negotiated timeout 6000 for client /192.168.33.202:52982 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:16:45,633] INFO Closed socket connection for client /192.168.33.202:52982 which had sessionid 0x100008e92cb0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:17:15,727] INFO Accepted socket connection from /192.168.33.202:52984 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:17:15,731] INFO Client attempting to establish new session at /192.168.33.202:52984 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:17:15,742] INFO Established session 0x100008e92cb0002 with negotiated timeout 20000 for client /192.168.33.202:52984 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:17:15,843] INFO Accepted socket connection from /192.168.33.202:52992 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:17:15,845] INFO Client attempting to establish new session at /192.168.33.202:52992 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:17:15,854] INFO Established session 0x100008e92cb0003 with negotiated timeout 20000 for client /192.168.33.202:52992 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:18:17,223] WARN Unable to read additional data from client sessionid 0x100008e92cb0002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:18:17,224] INFO Closed socket connection for client /192.168.33.202:52984 which had sessionid 0x100008e92cb0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:18:17,224] WARN Unable to read additional data from client sessionid 0x100008e92cb0003, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:18:17,225] INFO Closed socket connection for client /192.168.33.202:52992 which had sessionid 0x100008e92cb0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:18:18,251] WARN Connection broken for id 3, my id = 1, error =  (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$RecvWorker.run(QuorumCnxManager.java:1010)
[2019-03-18 17:18:18,252] WARN Interrupting SendWorker (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:18:18,252] WARN Interrupted while waiting for message on queue (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.pollSendQueue(QuorumCnxManager.java:1094)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.access$700(QuorumCnxManager.java:74)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$SendWorker.run(QuorumCnxManager.java:929)
[2019-03-18 17:18:18,253] WARN Send worker leaving thread (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:18:27,763] INFO Received connection request /192.168.33.202:37380 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:18:27,781] INFO Notification: 1 (message format version), 3 (n.leader), 0xa0000134f (n.zxid), 0x1 (n.round), LOOKING (n.state), 3 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:18:40,862] INFO Accepted socket connection from /192.168.33.202:53004 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:18:40,873] INFO Client attempting to establish new session at /192.168.33.202:53004 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:18:40,886] INFO Established session 0x100008e92cb0004 with negotiated timeout 20000 for client /192.168.33.202:53004 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:32,826] WARN Exception when following the leader (org.apache.zookeeper.server.quorum.Learner)
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.jute.BinaryInputArchive.readInt(BinaryInputArchive.java:63)
	at org.apache.zookeeper.server.quorum.QuorumPacket.deserialize(QuorumPacket.java:85)
	at org.apache.jute.BinaryInputArchive.readRecord(BinaryInputArchive.java:99)
	at org.apache.zookeeper.server.quorum.Learner.readPacket(Learner.java:153)
	at org.apache.zookeeper.server.quorum.Follower.followLeader(Follower.java:86)
	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:981)
[2019-03-18 17:20:32,826] INFO Unable to read additional data from server sessionid 0x200006f622e001c, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:32,826] WARN Connection broken for id 2, my id = 1, error =  (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$RecvWorker.run(QuorumCnxManager.java:1010)
[2019-03-18 17:20:32,827] WARN Interrupting SendWorker (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:20:32,827] INFO shutdown called (org.apache.zookeeper.server.quorum.Learner)
java.lang.Exception: shutdown Follower
	at org.apache.zookeeper.server.quorum.Follower.shutdown(Follower.java:169)
	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:985)
[2019-03-18 17:20:32,827] WARN Interrupted while waiting for message on queue (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2088)
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.pollSendQueue(QuorumCnxManager.java:1094)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.access$700(QuorumCnxManager.java:74)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager$SendWorker.run(QuorumCnxManager.java:929)
[2019-03-18 17:20:32,828] WARN Send worker leaving thread (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:20:32,828] INFO Closed socket connection for client /192.168.33.200:53614 which had sessionid 0x100008e92cb0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:32,829] INFO Closed socket connection for client /192.168.33.202:53004 which had sessionid 0x100008e92cb0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:32,830] INFO Shutting down (org.apache.zookeeper.server.quorum.FollowerZooKeeperServer)
[2019-03-18 17:20:32,830] INFO shutting down (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:32,830] INFO Shutting down (org.apache.zookeeper.server.quorum.FollowerRequestProcessor)
[2019-03-18 17:20:32,830] INFO Shutting down (org.apache.zookeeper.server.quorum.CommitProcessor)
[2019-03-18 17:20:32,830] INFO shutdown of request processor complete (org.apache.zookeeper.server.FinalRequestProcessor)
[2019-03-18 17:20:32,830] INFO FollowerRequestProcessor exited loop! (org.apache.zookeeper.server.quorum.FollowerRequestProcessor)
[2019-03-18 17:20:32,830] INFO CommitProcessor exited loop! (org.apache.zookeeper.server.quorum.CommitProcessor)
[2019-03-18 17:20:32,831] INFO Shutting down (org.apache.zookeeper.server.SyncRequestProcessor)
[2019-03-18 17:20:32,831] INFO SyncRequestProcessor exited! (org.apache.zookeeper.server.SyncRequestProcessor)
[2019-03-18 17:20:32,831] INFO LOOKING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:20:32,831] INFO New election. My id =  1, proposed zxid=0xa00001397 (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:32,831] INFO Notification: 1 (message format version), 1 (n.leader), 0xa00001397 (n.zxid), 0x2 (n.round), LOOKING (n.state), 1 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:32,832] WARN Cannot open channel to 2 at election address bdata2/192.168.33.201:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:558)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.toSend(QuorumCnxManager.java:534)
	at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.process(FastLeaderElection.java:454)
	at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.run(FastLeaderElection.java:435)
	at java.lang.Thread.run(Thread.java:748)
[2019-03-18 17:20:32,832] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:20:32,841] INFO Notification: 1 (message format version), 2 (n.leader), 0x900000018 (n.zxid), 0x1 (n.round), FOLLOWING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:32,844] INFO Notification: 1 (message format version), 3 (n.leader), 0xa00001397 (n.zxid), 0x2 (n.round), LOOKING (n.state), 3 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:32,844] INFO Notification: 1 (message format version), 3 (n.leader), 0xa00001397 (n.zxid), 0x2 (n.round), LOOKING (n.state), 1 (n.sid), 0xa (n.peerEpoch) LOOKING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:32,844] WARN Cannot open channel to 2 at election address bdata2/192.168.33.201:3888 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:558)
	at org.apache.zookeeper.server.quorum.QuorumCnxManager.toSend(QuorumCnxManager.java:534)
	at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.process(FastLeaderElection.java:454)
	at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.run(FastLeaderElection.java:435)
	at java.lang.Thread.run(Thread.java:748)
[2019-03-18 17:20:32,845] INFO Resolved hostname: bdata2 to address: bdata2/192.168.33.201 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:20:33,045] INFO FOLLOWING (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:20:33,045] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /data/bdata/data/zookeeper/version-2 snapdir /data/bdata/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:33,045] INFO FOLLOWING - LEADER ELECTION TOOK - 214 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:33,046] INFO Resolved hostname: bdata3 to address: bdata3/192.168.33.202 (org.apache.zookeeper.server.quorum.QuorumPeer)
[2019-03-18 17:20:33,047] WARN Unexpected exception, tries=0, connecting to bdata3/192.168.33.202:2888 (org.apache.zookeeper.server.quorum.Learner)
java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.zookeeper.server.quorum.Learner.connectToLeader(Learner.java:229)
	at org.apache.zookeeper.server.quorum.Follower.followLeader(Follower.java:72)
	at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:981)
[2019-03-18 17:20:33,095] INFO Accepted socket connection from /192.168.33.200:53794 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:33,097] WARN Exception causing close of session 0x0: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:33,097] INFO Closed socket connection for client /192.168.33.200:53794 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:33,193] INFO Accepted socket connection from /192.168.33.200:53796 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:33,194] WARN Exception causing close of session 0x0: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:33,194] INFO Closed socket connection for client /192.168.33.200:53796 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:33,238] INFO Opening socket connection to server bdata1/192.168.33.200:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:33,238] INFO Socket connection established to bdata1/192.168.33.200:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:33,238] INFO Accepted socket connection from /192.168.33.200:53798 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:33,239] WARN Exception causing close of session 0x0: ZooKeeperServer not running (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:33,240] INFO Closed socket connection for client /192.168.33.200:53798 (no session established for client) (org.apache.zookeeper.server.NIOServerCnxn)
[2019-03-18 17:20:33,240] INFO Unable to read additional data from server sessionid 0x200006f622e001c, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:33,640] INFO Opening socket connection to server bdata3/192.168.33.202:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:33,640] INFO Socket connection established to bdata3/192.168.33.202:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:33,641] INFO Unable to read additional data from server sessionid 0x200006f622e001c, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:34,057] INFO Getting a diff from the leader 0xa00001397 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:34,466] INFO Accepted socket connection from /192.168.33.200:53814 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:34,467] INFO Client attempting to renew session 0x200006f622e001f at /192.168.33.200:53814 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:34,467] INFO Revalidating client: 0x200006f622e001f (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:34,470] INFO Established session 0x200006f622e001f with negotiated timeout 20000 for client /192.168.33.200:53814 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:34,477] WARN Got zxid 0xb00000001 expected 0x1 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:34,909] INFO Opening socket connection to server bdata2/192.168.33.201:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:34,915] INFO Socket error occurred: bdata2/192.168.33.201:2181: Connection refused (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:35,470] INFO Opening socket connection to server bdata1/192.168.33.200:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:35,470] INFO Socket connection established to bdata1/192.168.33.200:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:35,470] INFO Accepted socket connection from /192.168.33.200:53818 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:35,470] INFO Client attempting to renew session 0x200006f622e001c at /192.168.33.200:53818 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:35,471] INFO Revalidating client: 0x200006f622e001c (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:35,472] INFO Established session 0x200006f622e001c with negotiated timeout 6000 for client /192.168.33.200:53818 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:35,472] INFO Session establishment complete on server bdata1/192.168.33.200:2181, sessionid = 0x200006f622e001c, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-03-18 17:20:35,711] INFO Accepted socket connection from /192.168.33.200:53820 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:35,711] INFO Client attempting to renew session 0x100008e92cb0000 at /192.168.33.200:53820 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:35,711] INFO Revalidating client: 0x100008e92cb0000 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:35,712] INFO Established session 0x100008e92cb0000 with negotiated timeout 20000 for client /192.168.33.200:53820 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:36,019] INFO Accepted socket connection from /192.168.33.202:53012 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:36,022] INFO Client attempting to renew session 0x100008e92cb0004 at /192.168.33.202:53012 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:36,022] INFO Revalidating client: 0x100008e92cb0004 (org.apache.zookeeper.server.quorum.Learner)
[2019-03-18 17:20:36,023] INFO Established session 0x100008e92cb0004 with negotiated timeout 20000 for client /192.168.33.202:53012 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:47,304] INFO Received connection request /192.168.33.201:54988 (org.apache.zookeeper.server.quorum.QuorumCnxManager)
[2019-03-18 17:20:47,307] INFO Notification: 1 (message format version), 2 (n.leader), 0xa00001397 (n.zxid), 0x1 (n.round), LOOKING (n.state), 2 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:47,310] INFO Notification: 1 (message format version), 3 (n.leader), 0xa00001397 (n.zxid), 0x2 (n.round), LOOKING (n.state), 2 (n.sid), 0xa (n.peerEpoch) FOLLOWING (my state) (org.apache.zookeeper.server.quorum.FastLeaderElection)
[2019-03-18 17:20:56,252] INFO Accepted socket connection from /192.168.33.201:58942 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-03-18 17:20:56,253] INFO Client attempting to establish new session at /192.168.33.201:58942 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:20:56,283] INFO Established session 0x1000093eede0000 with negotiated timeout 20000 for client /192.168.33.201:58942 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-03-18 17:24:48,721] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:34:48,725] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:44:48,724] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-03-18 17:54:48,724] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
